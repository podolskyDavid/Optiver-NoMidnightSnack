{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:26:13.668799Z",
     "start_time": "2023-11-19T03:26:12.886912Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "#------------------------Setup--------------------------#\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "        self.classifier_stock = nn.Linear(self.bert.config.hidden_size, 6) # stock classification head\n",
    "        self.classifier_sentiment = nn.Linear(self.bert.config.hidden_size, 3) # sentiment classification head\n",
    "        self.regression = nn.Linear(self.bert.config.hidden_size, 1) # regression head\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs[1]\n",
    "        stock_labels = self.classifier_stock(pooled_output)\n",
    "        sentiment_labels = self.classifier_sentiment(pooled_output)\n",
    "        regression_values = self.regression(pooled_output)\n",
    "        \n",
    "        return stock_labels, sentiment_labels, regression_values\n",
    "\n",
    "deployed_model = CustomBERTModel()\n",
    "deployed_model.load_state_dict(torch.load(\"082_081.pt\"))\n",
    "deployed_model = deployed_model.to(\"cpu\")\n",
    "\n",
    "def prepare_input(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Takes a string, tokenizes, and prepares it into expected format (list of token ids, attention masks, etc.) ready for model input\n",
    "\n",
    "    Arguments:\n",
    "    text -- string, Raw text string\n",
    "    tokenizer -- transformers.Tokenizer, Initialized tokenizer\n",
    "\n",
    "    Returns:\n",
    "    input_dict -- dictionary, Contains required inputs for model\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        truncation=True, \n",
    "        padding=True,\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Get the input ids and attention masks from tokenizer and convert to tensors\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # Put all tensor entries into a single dictionary\n",
    "    input_dict = {\n",
    "        'input_ids': input_ids,\n",
    "        'token_type_ids': torch.zeros(input_ids.shape, dtype=torch.long),\n",
    "        'attention_mask': attention_mask,\n",
    "    }\n",
    "    \n",
    "    return input_dict\n",
    "\n",
    "def predict_loaded_from_loaded_model(model, res, scaler):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: val.to(\"cpu\") for key, val in res.items()}  \n",
    "\n",
    "        stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs[\"token_type_ids\"])\n",
    "        \n",
    "        stock_label = torch.argmax(stock_labels_pred, dim=1).item()\n",
    "        sentiment_label = torch.argmax(sentiment_labels_pred, dim=1).item()\n",
    "        regression_value = scaler.inverse_transform(regression_values_pred.cpu().numpy()) # inverse transform of scaling\n",
    "\n",
    "    return stock_label, sentiment_label, regression_value[0][0]  # return the single value \n",
    "\n",
    "deployed_tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  1030,  6627,  7913, 18376,  1024, 26408,  5344,  7860,  1999,\n           2049,  4425,  4677,  1010, 12473,  1996,  4518,  1012,  1037,  7823,\n           4119,  2000,  9462,  1012,  1001,  4425, 24925,  8977,  6342,  2229,\n           1001,  6627, 14758,  2015,   102]]),\n 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = prepare_input(\"@TechTrends: Cisco faces challenges in its supply chain, affecting the stock. A tough challenge to overcome. #SupplyChainIssues #TechStocks\", deployed_tokenizer)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:26:14.956796Z",
     "start_time": "2023-11-19T03:26:14.938047Z"
    }
   },
   "id": "c882bc5c239bfbe3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 2, -0.032974098)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_loaded_from_loaded_model(deployed_model, res, scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:26:16.550987Z",
     "start_time": "2023-11-19T03:26:16.482271Z"
    }
   },
   "id": "71a9fd0e8d35e3e2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.1'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check pytorch version\n",
    "# update pytorch to 1.8.1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T00:39:52.747045Z",
     "start_time": "2023-11-19T00:39:52.738971Z"
    }
   },
   "id": "e0f9eccb3a1b10dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "feb9e064d4d96541"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8feb92db89b67d2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6310df41814dbfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "optiver-challenge",
   "language": "python",
   "display_name": "Python Optiver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
