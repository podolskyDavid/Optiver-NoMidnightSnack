{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning the cross classification-regression model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed82b1695cf510b6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# prepare the df\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "\n",
    "# MPS device\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# typical row:\n",
    "# \"@PharmaNews: Pfizer faces backlash over possible closure of regional office. #PharmaNews #RegionalOffice\",0.000000,0.000000,0.000000,-0.029512,0.000000\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:43:57.196500Z",
     "start_time": "2023-11-19T05:43:56.327422Z"
    }
   },
   "id": "be845befa38ca11f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:43:57.995262Z",
     "start_time": "2023-11-19T05:43:57.940078Z"
    }
   },
   "id": "b327e057e15b8a7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f34a6da144f38d3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-mini')\n",
    "\n",
    "# Define the stocks and sentiments\n",
    "stocks = ['None', 'NVDA', 'ING', 'SAN', 'PFE', 'CSCO']\n",
    "# None can only have None sentiment\n",
    "sentiments = ['None', '_pos', '_neg']\n",
    "# 3*5 + 1 = 16 classes in total and 1 regression head with log_returns\n",
    "\n",
    "# df has [\"SocialMediaFeed\", 'NVDA', 'ING', 'SAN', 'PFE', 'CSCO'] columns\n",
    "X_texts = df['SocialMediaFeed'].tolist()\n",
    "\n",
    "# Calculate which stock is affected by the news and get the log return value\n",
    "y_stock = []\n",
    "y_log_return = []\n",
    "for i, row in df.iterrows():\n",
    "    affected_stock = \"None\"\n",
    "    log_return_val = 0.0\n",
    "    for stock in stocks[1:]:\n",
    "        if row[stock] != 0:\n",
    "            affected_stock = stock\n",
    "            log_return_val = row[stock]\n",
    "            break\n",
    "    y_stock.append(affected_stock)\n",
    "    y_log_return.append(log_return_val)\n",
    "\n",
    "y_stock = [stocks.index(s) for s in y_stock]\n",
    "\n",
    "X_train_texts, X_val_texts, y_train_stock, y_val_stock, y_train_val, y_val_val = train_test_split(X_texts, y_stock, y_log_return, test_size=.2)\n",
    "\n",
    "# Scale regression target (log returns) with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y_train_val_scaled = scaler.fit_transform(np.array(y_train_val).reshape(-1, 1)).flatten().astype('float32')\n",
    "y_val_val_scaled = scaler.transform(np.array(y_val_val).reshape(-1, 1)).flatten().astype('float32')\n",
    "\n",
    "# Set up labels for sentiment analysis\n",
    "train_sentiments = [sentiments.index(\"_pos\") if val > 0.000001 else sentiments.index(\"_neg\") if val < -0.000001 else sentiments.index(\"None\") for val in y_train_val]\n",
    "val_sentiments = [sentiments.index(\"_pos\") if val > 0.000001 else sentiments.index(\"_neg\") if val < -0.000001 else sentiments.index(\"None\") for val in y_val_val]\n",
    "\n",
    "# Next, tokenize the texts\n",
    "train_encodings = tokenizer(X_train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val_texts, truncation=True, padding=True)\n",
    "\n",
    "# Define the custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, stock_labels, sentiment_labels, values):\n",
    "        self.encodings = {key: torch.tensor(val, device=device) for key, val in encodings.items()}\n",
    "        self.stock_labels = torch.tensor(stock_labels).to(device)\n",
    "        self.sentiment_labels = torch.tensor(sentiment_labels).to(device)\n",
    "        self.values = torch.tensor(values).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"stock_labels\"] = self.stock_labels[idx]\n",
    "        item[\"sentiment_labels\"] = self.sentiment_labels[idx]\n",
    "        item[\"values\"] = self.values[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stock_labels)\n",
    "\n",
    "# Create the custom dataset\n",
    "train_dataset = CustomDataset(train_encodings, y_train_stock, train_sentiments, y_train_val_scaled)\n",
    "val_dataset = CustomDataset(val_encodings, y_val_stock, val_sentiments, y_val_val_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:43:59.477394Z",
     "start_time": "2023-11-19T05:43:58.304272Z"
    }
   },
   "id": "d8cbe0dc0308b7aa"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# export scaler\n",
    "import pickle\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:43:59.495414Z",
     "start_time": "2023-11-19T05:43:59.452684Z"
    }
   },
   "id": "677cd5c55a13e33d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([  101,  1030,  6887, 27292,  4887, 17299,  3686,  1024,  1052,  8873,\n          6290,  1005,  1055,  1053,  2475, 16565,  2453,  2991,  2917, 10908,\n          1012,  3422,  2041,  2005,  4518, 28892,  1012,  1001, 16565,  6279,\n         13701,  1001,  6887, 27292,  7231,  9333,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0]),\n 'stock_labels': tensor(0),\n 'sentiment_labels': tensor(0),\n 'values': tensor(-0.0054)}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataset[0]\n",
    "\n",
    "# typical output:\n",
    "# {'input_ids': tensor([  101,  1030,  6887, 27292,  4887, 17299,  3686,  1024,  1052,  8873,\n",
    "#           6290,  1005,  1055,  1053,  2475, 16565,  2453,  2991,  2917, 10908,\n",
    "#           1012,  3422,  2041,  2005,  4518, 28892,  1012,  1001, 16565,  6279,\n",
    "#          13701,  1001,  6887, 27292,  7231,  9333,   102,     0,     0,     0,\n",
    "#              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "#              0,     0,     0,     0,     0]),\n",
    "#  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#          0, 0, 0, 0, 0, 0, 0]),\n",
    "#  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#          0, 0, 0, 0, 0, 0, 0]),\n",
    "#  'stock_labels': tensor(0),\n",
    "#  'sentiment_labels': tensor(0),\n",
    "#  'values': tensor(-0.0054)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:43:59.852791Z",
     "start_time": "2023-11-19T05:43:59.823389Z"
    }
   },
   "id": "91e0a3e864c1d076"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T05:44:00.209459Z",
     "start_time": "2023-11-19T05:44:00.161996Z"
    }
   },
   "id": "6dc18131196500de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf6ee1c150303229"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-mini')\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        # self.dense = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size, device=device)\n",
    "        self.classifier_stock = nn.Linear(self.bert.config.hidden_size, 6) # stock classification head\n",
    "        self.classifier_sentiment = nn.Linear(self.bert.config.hidden_size, 3) # sentiment classification head\n",
    "        self.regression = nn.Linear(self.bert.config.hidden_size, 1) # regression head\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs[1]\n",
    "        # pooled_output = self.dense(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        stock_labels = self.classifier_stock(pooled_output)\n",
    "        sentiment_labels = self.classifier_sentiment(pooled_output)\n",
    "        regression_values = self.regression(pooled_output)\n",
    "        \n",
    "        return stock_labels, sentiment_labels, regression_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:01:03.728605Z",
     "start_time": "2023-11-19T06:01:03.693076Z"
    }
   },
   "id": "a70848fccb9d92d3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(BertModel.from_pretrained('prajjwal1/bert-mini').encoder.layer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:01:10.622091Z",
     "start_time": "2023-11-19T06:01:10.098799Z"
    }
   },
   "id": "43c23ba3231c2cf4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:01:11.934597Z",
     "start_time": "2023-11-19T06:01:11.889980Z"
    }
   },
   "id": "89b6fbe75f2b375b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "728fa25d6c2cf989"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "l1_lambda = 0.01\n",
    "stock_loss_weight = 1\n",
    "sentiment_loss_weight = 3\n",
    "regression_loss_weight = 2\n",
    "\n",
    "def train(dataloader, model, optimizer):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters()).detach()\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0    # initialize total loss to 0\n",
    "    for batch in dataloader:\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get the inputs and labels\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "        stock_labels = inputs.pop('stock_labels').to(device)\n",
    "        sentiment_labels = inputs.pop('sentiment_labels').to(device)\n",
    "        values = inputs.pop('values').to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(**inputs)\n",
    "        \n",
    "        sentiment_weights = torch.Tensor([1, 2, 2]).to(device)  \n",
    "        stock_weights = torch.Tensor([1, 3, 4, 4, 3, 2]).to(device)\n",
    "        \n",
    "        # compute the loss\n",
    "        stock_loss = CrossEntropyLoss(weight=stock_weights)(stock_labels_pred.view(-1, 6), stock_labels.view(-1))\n",
    "        sentiment_loss = CrossEntropyLoss(weight=sentiment_weights)(sentiment_labels_pred.view(-1, 3), sentiment_labels.view(-1))\n",
    "        regression_loss = MSELoss()(regression_values_pred.view(-1), values.view(-1))\n",
    "        \n",
    "        total_loss = stock_loss_weight*stock_loss + sentiment_loss_weight*sentiment_loss + regression_loss_weight*regression_loss #+ l1_lambda * l1_norm\n",
    "\n",
    "        # backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(dataloader, model):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters()).detach()\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {key: val for key, val in batch.items()}\n",
    "            stock_labels = inputs.pop('stock_labels')\n",
    "            sentiment_labels = inputs.pop('sentiment_labels')\n",
    "            values = inputs.pop('values')\n",
    "            \n",
    "            stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(**inputs)           \n",
    "\n",
    "            stock_loss = CrossEntropyLoss()(stock_labels_pred.view(-1, 6), stock_labels)\n",
    "            sentiment_loss = CrossEntropyLoss()(sentiment_labels_pred.view(-1, 3), sentiment_labels)\n",
    "            regression_loss = MSELoss()(regression_values_pred.view(-1), values.view(-1))\n",
    "            \n",
    "            total_loss += stock_loss_weight*stock_loss + sentiment_loss_weight*sentiment_loss + regression_loss_weight*regression_loss #+ l1_lambda * l1_norm\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:01:12.933114Z",
     "start_time": "2023-11-19T06:01:12.912191Z"
    }
   },
   "id": "3542c6727ef601a5"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "Train loss 0.06904063373804092\n",
      "Validation loss 6.766324520111084\n",
      "Validation loss decreased from None to 6.766324520111084.\n",
      "Epoch 2/50\n",
      "----------\n",
      "Train loss 0.06516032665967941\n",
      "Validation loss 6.411446571350098\n",
      "Validation loss decreased from 6.766324520111084 to 6.411446571350098.\n",
      "Epoch 3/50\n",
      "----------\n",
      "Train loss 0.1812034249305725\n",
      "Validation loss 6.256017208099365\n",
      "Validation loss decreased from 6.411446571350098 to 6.256017208099365.\n",
      "Epoch 4/50\n",
      "----------\n",
      "Train loss 0.03919582441449165\n",
      "Validation loss 5.709074020385742\n",
      "Validation loss decreased from 6.256017208099365 to 5.709074020385742.\n",
      "Epoch 5/50\n",
      "----------\n",
      "Train loss 0.05612219497561455\n",
      "Validation loss 5.268950462341309\n",
      "Validation loss decreased from 5.709074020385742 to 5.268950462341309.\n",
      "Epoch 6/50\n",
      "----------\n",
      "Train loss 0.2042253315448761\n",
      "Validation loss 5.110407829284668\n",
      "Validation loss decreased from 5.268950462341309 to 5.110407829284668.\n",
      "Epoch 7/50\n",
      "----------\n",
      "Train loss 0.11633892357349396\n",
      "Validation loss 4.699721336364746\n",
      "Validation loss decreased from 5.110407829284668 to 4.699721336364746.\n",
      "Epoch 8/50\n",
      "----------\n",
      "Train loss 0.054578009992837906\n",
      "Validation loss 4.5562052726745605\n",
      "Validation loss decreased from 4.699721336364746 to 4.5562052726745605.\n",
      "Epoch 9/50\n",
      "----------\n",
      "Train loss 0.09319550544023514\n",
      "Validation loss 4.312544345855713\n",
      "Validation loss decreased from 4.5562052726745605 to 4.312544345855713.\n",
      "Epoch 10/50\n",
      "----------\n",
      "Train loss 0.01794041320681572\n",
      "Validation loss 4.174688339233398\n",
      "Validation loss decreased from 4.312544345855713 to 4.174688339233398.\n",
      "Epoch 11/50\n",
      "----------\n",
      "Train loss 0.019381655380129814\n",
      "Validation loss 3.8681843280792236\n",
      "Validation loss decreased from 4.174688339233398 to 3.8681843280792236.\n",
      "Epoch 12/50\n",
      "----------\n",
      "Train loss 0.13898412883281708\n",
      "Validation loss 3.8316128253936768\n",
      "Validation loss decreased from 3.8681843280792236 to 3.8316128253936768.\n",
      "Saving model...\n",
      "Epoch 13/50\n",
      "----------\n",
      "Train loss 0.04318845644593239\n",
      "Validation loss 3.7830545902252197\n",
      "Validation loss decreased from 3.8316128253936768 to 3.7830545902252197.\n",
      "Saving model...\n",
      "Epoch 14/50\n",
      "----------\n",
      "Train loss 0.05493341013789177\n",
      "Validation loss 3.786280632019043\n",
      "Epoch 15/50\n",
      "----------\n",
      "Train loss 0.07296726852655411\n",
      "Validation loss 3.6602542400360107\n",
      "Validation loss decreased from 3.7830545902252197 to 3.6602542400360107.\n",
      "Saving model...\n",
      "Epoch 16/50\n",
      "----------\n",
      "Train loss 0.061223626136779785\n",
      "Validation loss 3.7287497520446777\n",
      "Epoch 17/50\n",
      "----------\n",
      "Train loss 0.04349537938833237\n",
      "Validation loss 3.5880537033081055\n",
      "Validation loss decreased from 3.6602542400360107 to 3.5880537033081055.\n",
      "Saving model...\n",
      "Epoch 18/50\n",
      "----------\n",
      "Train loss 0.02813917025923729\n",
      "Validation loss 3.3219611644744873\n",
      "Validation loss decreased from 3.5880537033081055 to 3.3219611644744873.\n",
      "Saving model...\n",
      "Epoch 19/50\n",
      "----------\n",
      "Train loss 0.0576079860329628\n",
      "Validation loss 3.4328999519348145\n",
      "Epoch 20/50\n",
      "----------\n",
      "Train loss 0.06082218512892723\n",
      "Validation loss 3.306363582611084\n",
      "Validation loss decreased from 3.3219611644744873 to 3.306363582611084.\n",
      "Saving model...\n",
      "Epoch 21/50\n",
      "----------\n",
      "Train loss 0.009546888060867786\n",
      "Validation loss 3.3455958366394043\n",
      "Epoch 22/50\n",
      "----------\n",
      "Train loss 0.034734081476926804\n",
      "Validation loss 3.3518311977386475\n",
      "Epoch 23/50\n",
      "----------\n",
      "Train loss 0.019304070621728897\n",
      "Validation loss 3.2698564529418945\n",
      "Validation loss decreased from 3.306363582611084 to 3.2698564529418945.\n",
      "Saving model...\n",
      "Epoch 24/50\n",
      "----------\n",
      "Train loss 0.13146011531352997\n",
      "Validation loss 3.0535731315612793\n",
      "Validation loss decreased from 3.2698564529418945 to 3.0535731315612793.\n",
      "Saving model...\n",
      "Epoch 25/50\n",
      "----------\n",
      "Train loss 0.04121040925383568\n",
      "Validation loss 3.3661582469940186\n",
      "Epoch 26/50\n",
      "----------\n",
      "Train loss 0.02764367312192917\n",
      "Validation loss 3.114976167678833\n",
      "Epoch 27/50\n",
      "----------\n",
      "Train loss 0.0538615845143795\n",
      "Validation loss 3.152352809906006\n",
      "Epoch 28/50\n",
      "----------\n",
      "Train loss 0.013930756598711014\n",
      "Validation loss 3.138909339904785\n",
      "Epoch 29/50\n",
      "----------\n",
      "Train loss 0.05907031148672104\n",
      "Validation loss 3.2299394607543945\n",
      "Epoch 30/50\n",
      "----------\n",
      "Train loss 0.017037272453308105\n",
      "Validation loss 3.3778560161590576\n",
      "Epoch 31/50\n",
      "----------\n",
      "Train loss 0.04396522045135498\n",
      "Validation loss 3.2247800827026367\n",
      "Epoch 32/50\n",
      "----------\n",
      "Train loss 0.035094451159238815\n",
      "Validation loss 3.274379253387451\n",
      "Epoch 33/50\n",
      "----------\n",
      "Train loss 0.004680724814534187\n",
      "Validation loss 3.1987218856811523\n",
      "Epoch 34/50\n",
      "----------\n",
      "Train loss 0.026997847482562065\n",
      "Validation loss 3.307913303375244\n",
      "No improvement in validation loss for 10 epochs. Stopping...\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import copy\n",
    "\n",
    "model = CustomBERTModel().to(device)\n",
    "# for param in model.bert.encoder.layer[-2:].parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 50\n",
    "grad_clip = 1.0\n",
    "best_loss = None\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "early_stopping = False\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss = train(train_loader, model, optimizer)\n",
    "\n",
    "    # Gradient clipping\n",
    "    clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "    print(f'Train loss {train_loss}')\n",
    "\n",
    "    val_loss = validate(val_loader, model)\n",
    "    print(f'Validation loss {val_loss}')\n",
    "\n",
    "    # Save the model if validation loss decreases\n",
    "    if best_loss is None or val_loss < best_loss:\n",
    "        print(f'Validation loss decreased from {None if best_loss is None else best_loss} to {val_loss}.')\n",
    "        no_improve = 0\n",
    "        best_loss = val_loss\n",
    "        if epoch > 10:\n",
    "            print(f'Saving model...')\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    if no_improve >= patience:\n",
    "        print(f'No improvement in validation loss for {patience} epochs. Stopping...')\n",
    "        early_stopping = True\n",
    "        break\n",
    "\n",
    "if early_stopping:\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "print('Training complete')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:03:38.095426Z",
     "start_time": "2023-11-19T06:01:15.161282Z"
    }
   },
   "id": "4c81997c2e0cc531"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:04:13.593867Z",
     "start_time": "2023-11-19T06:04:13.561913Z"
    }
   },
   "id": "e920ffb65a83057e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc11a355af8d5cd"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def validate(dataloader, model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    stock_outputs, sentiment_outputs, value_outputs = [], [], []\n",
    "    stock_labels, sentiment_labels, values = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "            batch_stock_labels = inputs.pop('stock_labels').to(device)\n",
    "            batch_sentiment_labels = inputs.pop('sentiment_labels').to(device)\n",
    "            batch_values = inputs.pop('values').to(device)\n",
    "            \n",
    "            stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(**inputs)\n",
    "            \n",
    "            stock_loss = CrossEntropyLoss()(stock_labels_pred.view(-1, 6), batch_stock_labels.view(-1))\n",
    "            sentiment_loss = CrossEntropyLoss()(sentiment_labels_pred.view(-1, 3), batch_sentiment_labels.view(-1))\n",
    "            regression_loss = MSELoss()(regression_values_pred.view(-1), batch_values.view(-1))\n",
    "            \n",
    "            total_loss += stock_loss + sentiment_loss + regression_loss\n",
    "\n",
    "            # store predictions and true labels for metric computation\n",
    "            stock_outputs.extend(torch.argmax(stock_labels_pred, dim=1).tolist())\n",
    "            sentiment_outputs.extend(torch.argmax(sentiment_labels_pred, dim=1).tolist())\n",
    "            value_outputs.extend(regression_values_pred.tolist())\n",
    "\n",
    "            stock_labels.extend(batch_stock_labels.tolist())\n",
    "            sentiment_labels.extend(batch_sentiment_labels.tolist())\n",
    "            values.extend(batch_values.tolist())\n",
    "\n",
    "    return total_loss / len(dataloader), (stock_outputs, sentiment_outputs, value_outputs), (stock_labels, sentiment_labels, values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:01.948593Z",
     "start_time": "2023-11-19T06:07:01.925296Z"
    }
   },
   "id": "f44fb4ca942bf503"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 1.6258095502853394\n",
      "Stock Classification F1:  0.8238874194457986 \n",
      "Confusion Matrix:\n",
      " [[119   5   2   4   4   2]\n",
      " [  2  20   0   0   0   0]\n",
      " [  4   0  12   0   0   0]\n",
      " [  5   0   0  16   0   0]\n",
      " [  4   0   0   0  18   0]\n",
      " [  9   0   0   0   0  11]]\n",
      "Sentiment Classification F1:  0.8234362395055037 \n",
      "Confusion Matrix:\n",
      " [[117   4  15]\n",
      " [  8  42   1]\n",
      " [ 13   1  36]]\n",
      "Regression RMSE:  1.2860907316207886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([237, 1])) that is different to the input size (torch.Size([237])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "val_loss, (stock_outputs, sentiment_outputs, value_outputs), (stock_labels, sentiment_labels, values) = validate(val_loader, model)\n",
    "print(f'Validation loss {val_loss}')\n",
    "\n",
    "# compute confusion matrix, F1 score, etc\n",
    "stock_cm = confusion_matrix(stock_labels, stock_outputs)\n",
    "sentiment_cm = confusion_matrix(sentiment_labels, sentiment_outputs)\n",
    "\n",
    "stock_f1 = f1_score(stock_labels, stock_outputs, average=\"weighted\")\n",
    "sentiment_f1 = f1_score(sentiment_labels, sentiment_outputs, average=\"weighted\")\n",
    "\n",
    "print('Stock Classification F1: ', stock_f1, '\\nConfusion Matrix:\\n', stock_cm)\n",
    "print('Sentiment Classification F1: ', sentiment_f1, '\\nConfusion Matrix:\\n', sentiment_cm)\n",
    "\n",
    "# for regression, we use root mean squared error (RMSE) instead of F1, etc.\n",
    "value_rmse = np.sqrt(MSELoss()(torch.tensor(values, device=device).cpu(), torch.tensor(value_outputs, device=device).cpu())) \n",
    "print('Regression RMSE: ', value_rmse.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:03.037897Z",
     "start_time": "2023-11-19T06:07:02.775965Z"
    }
   },
   "id": "d5a2471b0d01ca44"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.8533780574798584\n",
      "Stock Classification F1:  0.9174713675354278 \n",
      "Confusion Matrix:\n",
      " [[499  20   7   7  11   4]\n",
      " [  0  89   0   0   0   0]\n",
      " [  3   0  73   1   0   0]\n",
      " [  5   0   0  70   0   0]\n",
      " [  3   0   0   0  67   0]\n",
      " [ 17   0   0   0   0  69]]\n",
      "Sentiment Classification F1:  0.9537804469940004 \n",
      "Confusion Matrix:\n",
      " [[515   7  26]\n",
      " [  8 190   0]\n",
      " [  3   0 196]]\n",
      "Regression RMSE:  1.3598183393478394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([945, 1])) that is different to the input size (torch.Size([945])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train_loss, (stock_outputs, sentiment_outputs, value_outputs), (stock_labels, sentiment_labels, values) = validate(train_loader, model)\n",
    "print(f'Train loss {train_loss}')\n",
    "\n",
    "# compute confusion matrix, F1 score, etc\n",
    "stock_cm = confusion_matrix(stock_labels, stock_outputs)\n",
    "sentiment_cm = confusion_matrix(sentiment_labels, sentiment_outputs)\n",
    "\n",
    "stock_f1 = f1_score(stock_labels, stock_outputs, average=\"weighted\")\n",
    "sentiment_f1 = f1_score(sentiment_labels, sentiment_outputs, average=\"weighted\")\n",
    "\n",
    "print('Stock Classification F1: ', stock_f1, '\\nConfusion Matrix:\\n', stock_cm)\n",
    "print('Sentiment Classification F1: ', sentiment_f1, '\\nConfusion Matrix:\\n', sentiment_cm)\n",
    "\n",
    "# for regression, we use root mean squared error (RMSE) instead of F1, etc.\n",
    "value_rmse = np.sqrt(MSELoss()(torch.tensor(values, device=device).cpu(), torch.tensor(value_outputs, device=device).cpu())) \n",
    "print('Regression RMSE: ', value_rmse.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:08.286299Z",
     "start_time": "2023-11-19T06:07:07.031185Z"
    }
   },
   "id": "112e5a7550f99c01"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:11.996023Z",
     "start_time": "2023-11-19T06:07:11.969436Z"
    }
   },
   "id": "99bcf3b744c2c5f1"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::linear_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Quantize\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m model_q \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize_dynamic\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLinear\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqint8\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(model_q)\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:468\u001B[0m, in \u001B[0;36mquantize_dynamic\u001B[0;34m(model, qconfig_spec, dtype, mapping, inplace)\u001B[0m\n\u001B[1;32m    466\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    467\u001B[0m propagate_qconfig_(model, qconfig_spec)\n\u001B[0;32m--> 468\u001B[0m \u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:553\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inplace:\n\u001B[1;32m    552\u001B[0m     module \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(module)\n\u001B[0;32m--> 553\u001B[0m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remove_qconfig:\n\u001B[1;32m    557\u001B[0m     _remove_qconfig(module)\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:591\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[0;32m--> 591\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[1;32m    592\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:591\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[0;32m--> 591\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[1;32m    592\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "    \u001B[0;31m[... skipping similar frames: _convert at line 591 (3 times)]\u001B[0m\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:591\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[0;32m--> 591\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[1;32m    592\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:593\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[1;32m    591\u001B[0m         _convert(mod, mapping, \u001B[38;5;28;01mTrue\u001B[39;00m,  \u001B[38;5;66;03m# inplace\u001B[39;00m\n\u001B[1;32m    592\u001B[0m                  is_reference, convert_custom_config_dict)\n\u001B[0;32m--> 593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m \u001B[43mswap_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_module_class_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    596\u001B[0m     module\u001B[38;5;241m.\u001B[39m_modules[key] \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:626\u001B[0m, in \u001B[0;36mswap_module\u001B[0;34m(mod, mapping, custom_module_class_mapping)\u001B[0m\n\u001B[1;32m    624\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m qmod\u001B[38;5;241m.\u001B[39mfrom_float(mod, weight_qparams)\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 626\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m \u001B[43mqmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_float\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m     swapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped:\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001B[39;00m\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.from_float\u001B[0;34m(cls, mod)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported dtype specified for dynamic quantized Linear!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 116\u001B[0m qlinear \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m qlinear\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, mod\u001B[38;5;241m.\u001B[39mbias)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m qlinear\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py:40\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias_, dtype)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_features, out_features, bias_\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mqint8):\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m# We don't muck around with buffers or attributes or anything here\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;66;03m# to keep the module simple. *everything* is simply a Python attribute.\u001B[39;00m\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# Serialization logic is explicitly handled in the below serialization and\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# deserialization modules\u001B[39;00m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:151\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias_, dtype)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported dtype specified for quantized Linear!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mLinearPackedParams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, bias)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:27\u001B[0m, in \u001B[0;36mLinearPackedParams.__init__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     26\u001B[0m     wq \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_weight_bias\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:32\u001B[0m, in \u001B[0;36mLinearPackedParams.set_weight_bias\u001B[0;34m(self, weight, bias)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_weight_bias\u001B[39m(\u001B[38;5;28mself\u001B[39m, weight: torch\u001B[38;5;241m.\u001B[39mTensor, bias: Optional[torch\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mqint8:\n\u001B[0;32m---> 32\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_prepack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mquantized\u001B[38;5;241m.\u001B[39mlinear_prepack_fp16(weight, bias)\n",
      "File \u001B[0;32m~/Installations/miniforge3/envs/optiver-challenge/lib/python3.11/site-packages/torch/_ops.py:760\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    759\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Didn't find engine for operation quantized::linear_prepack NoQEngine"
     ]
    }
   ],
   "source": [
    "# quantized model\n",
    "import torch.quantization\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "# Quantize\n",
    "model_q = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print(model_q)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:12.413215Z",
     "start_time": "2023-11-19T06:07:12.352661Z"
    }
   },
   "id": "95dfe415fdd766dc"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:15.987276Z",
     "start_time": "2023-11-19T06:07:15.967238Z"
    }
   },
   "id": "41fe63f4b0264d58"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:16.494373Z",
     "start_time": "2023-11-19T06:07:16.488053Z"
    }
   },
   "id": "9c7ac88b53d7efe9"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:16.799308Z",
     "start_time": "2023-11-19T06:07:16.768007Z"
    }
   },
   "id": "ee91c6bd91d1d06c"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def predict(model, dataset_item, scaler):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: val.unsqueeze(0).to(device) for key, val in dataset_item.items()} # unsqueeze to mimic batch dim\n",
    "        inputs.pop('stock_labels')\n",
    "        inputs.pop('sentiment_labels')\n",
    "        inputs.pop('values')\n",
    "\n",
    "        stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(**inputs)\n",
    "        \n",
    "        stock_label = torch.argmax(stock_labels_pred, dim=1).item()\n",
    "        sentiment_label = torch.argmax(sentiment_labels_pred, dim=1).item()\n",
    "        regression_value = scaler.inverse_transform(regression_values_pred.cpu().numpy()) # inverse transform of scaling\n",
    "\n",
    "    return stock_label, sentiment_label, regression_value[0][0]  # return the single value from the 2D array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:17.110792Z",
     "start_time": "2023-11-19T06:07:17.078484Z"
    }
   },
   "id": "76e29a7bb315aaee"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.010525597259402275\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 1:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0019254387589171529\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 2:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 9.125718861469068e-06\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 3:\n",
      "Predicted stock_class: 1, sentiment_class: 2, value: -0.0347357876598835\n",
      "True stock_class: 1, sentiment_class: 2, value: -0.025382427936891654\n",
      "---\n",
      "Example 4:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0011488996678963304\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 5:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0019121920922771096\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 6:\n",
      "Predicted stock_class: 3, sentiment_class: 2, value: -0.04745299741625786\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.051920877181305246\n",
      "---\n",
      "Example 7:\n",
      "Predicted stock_class: 4, sentiment_class: 2, value: -0.017843058332800865\n",
      "True stock_class: 4, sentiment_class: 2, value: -0.003942571729105047\n",
      "---\n",
      "Example 8:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.00018448232731316239\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 9:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.030342571437358856\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 10:\n",
      "Predicted stock_class: 1, sentiment_class: 0, value: -0.007604079786688089\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 11:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0032165111042559147\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 12:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.03844209760427475\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.016421926480578566\n",
      "---\n",
      "Example 13:\n",
      "Predicted stock_class: 4, sentiment_class: 1, value: 0.028939172625541687\n",
      "True stock_class: 4, sentiment_class: 1, value: 0.028254835404572118\n",
      "---\n",
      "Example 14:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.008057885803282261\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 15:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.002200303366407752\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 16:\n",
      "Predicted stock_class: 3, sentiment_class: 2, value: -0.03783772513270378\n",
      "True stock_class: 3, sentiment_class: 2, value: -0.04776459411098506\n",
      "---\n",
      "Example 17:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.00031974728335626423\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 18:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0002775267348624766\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 19:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.003934120759367943\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 20:\n",
      "Predicted stock_class: 2, sentiment_class: 1, value: 0.051312725991010666\n",
      "True stock_class: 2, sentiment_class: 1, value: 0.06012901673245026\n",
      "---\n",
      "Example 21:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.017162885516881943\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 22:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.03212326392531395\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.034213932192495904\n",
      "---\n",
      "Example 23:\n",
      "Predicted stock_class: 4, sentiment_class: 1, value: 0.04802342504262924\n",
      "True stock_class: 4, sentiment_class: 1, value: 0.06375919672164315\n",
      "---\n",
      "Example 24:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0058066993951797485\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 25:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.00044478356721810997\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 26:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.034087248146533966\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.025311378508707485\n",
      "---\n",
      "Example 27:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0009244455141015351\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 28:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.00035005013342015445\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 29:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0015236912295222282\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 30:\n",
      "Predicted stock_class: 2, sentiment_class: 1, value: 0.02158840000629425\n",
      "True stock_class: 2, sentiment_class: 1, value: 0.034305430996945364\n",
      "---\n",
      "Example 31:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.00870144460350275\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 32:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0021483898162841797\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 33:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0025056805461645126\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 34:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0014267518417909741\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 35:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.001028483733534813\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 36:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.002954406663775444\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 37:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0014614546671509743\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 38:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0017545876326039433\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 39:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.007865511812269688\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 40:\n",
      "Predicted stock_class: 2, sentiment_class: 1, value: 0.03985600546002388\n",
      "True stock_class: 2, sentiment_class: 1, value: 0.060991605724682346\n",
      "---\n",
      "Example 41:\n",
      "Predicted stock_class: 3, sentiment_class: 2, value: -0.04327144846320152\n",
      "True stock_class: 3, sentiment_class: 2, value: -0.05526521248561586\n",
      "---\n",
      "Example 42:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0014370100107043982\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 43:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0021590834949165583\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 44:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.005086687859147787\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 45:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.03206983953714371\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.023212836052390932\n",
      "---\n",
      "Example 46:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.001017815782688558\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 47:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.011370854452252388\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 48:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.046095021069049835\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.05757696371328013\n",
      "---\n",
      "Example 49:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0017377041513100266\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 50:\n",
      "Predicted stock_class: 3, sentiment_class: 1, value: 0.04603416472673416\n",
      "True stock_class: 3, sentiment_class: 1, value: 0.02446829916456217\n",
      "---\n",
      "Example 51:\n",
      "Predicted stock_class: 3, sentiment_class: 0, value: -0.016298256814479828\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 52:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.004017907194793224\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 53:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0004124284314457327\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 54:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.03604172170162201\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.03310454759150248\n",
      "---\n",
      "Example 55:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0011197467101737857\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 56:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.024021010845899582\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.022032667126262995\n",
      "---\n",
      "Example 57:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.002316746860742569\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 58:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0013723965967074037\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 59:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -9.660790237830952e-05\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 60:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0027578887529671192\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 61:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0007120842928998172\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 62:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.015589998103678226\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 63:\n",
      "Predicted stock_class: 4, sentiment_class: 1, value: 0.014074851758778095\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 64:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.005063556134700775\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 65:\n",
      "Predicted stock_class: 4, sentiment_class: 2, value: -0.04279119521379471\n",
      "True stock_class: 4, sentiment_class: 2, value: -0.05058030836713812\n",
      "---\n",
      "Example 66:\n",
      "Predicted stock_class: 4, sentiment_class: 1, value: 0.04193725436925888\n",
      "True stock_class: 4, sentiment_class: 1, value: 0.025184576852438172\n",
      "---\n",
      "Example 67:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0027591015677899122\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 68:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.00041788918315432966\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 69:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.039012353867292404\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.06369946452978173\n",
      "---\n",
      "Example 70:\n",
      "Predicted stock_class: 3, sentiment_class: 2, value: -0.03885383903980255\n",
      "True stock_class: 3, sentiment_class: 2, value: -0.03933526397973119\n",
      "---\n",
      "Example 71:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.005158907733857632\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 72:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0011030911700800061\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 73:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.040895916521549225\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.05675522818572393\n",
      "---\n",
      "Example 74:\n",
      "Predicted stock_class: 3, sentiment_class: 1, value: 0.03101561777293682\n",
      "True stock_class: 3, sentiment_class: 1, value: 0.01980420865657422\n",
      "---\n",
      "Example 75:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0018668484408408403\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 76:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0009398757247254252\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 77:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0014588742051273584\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 78:\n",
      "Predicted stock_class: 2, sentiment_class: 1, value: 0.0455327071249485\n",
      "True stock_class: 2, sentiment_class: 1, value: 0.02035190132545221\n",
      "---\n",
      "Example 79:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.002661263570189476\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 80:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.003980215173214674\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 81:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0021220496855676174\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 82:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -4.500186332734302e-05\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 83:\n",
      "Predicted stock_class: 1, sentiment_class: 1, value: 0.0364866703748703\n",
      "True stock_class: 1, sentiment_class: 1, value: 0.026124971025905438\n",
      "---\n",
      "Example 84:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0024816994555294514\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 85:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0018910928629338741\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 86:\n",
      "Predicted stock_class: 2, sentiment_class: 2, value: -0.025439096614718437\n",
      "True stock_class: 2, sentiment_class: 2, value: -0.022868890311522196\n",
      "---\n",
      "Example 87:\n",
      "Predicted stock_class: 3, sentiment_class: 1, value: 0.0231627244502306\n",
      "True stock_class: 3, sentiment_class: 1, value: 0.022927007203779298\n",
      "---\n",
      "Example 88:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0035920871887356043\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 89:\n",
      "Predicted stock_class: 1, sentiment_class: 0, value: -0.012334589846432209\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 90:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.007924695499241352\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 91:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.000617167737800628\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 92:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0006457279669120908\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 93:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0037729828618466854\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 94:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.004225906915962696\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 95:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.003008301369845867\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 96:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: -0.0007244277512654662\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 97:\n",
      "Predicted stock_class: 1, sentiment_class: 2, value: -0.02245345152914524\n",
      "True stock_class: 1, sentiment_class: 2, value: -0.02347310579753491\n",
      "---\n",
      "Example 98:\n",
      "Predicted stock_class: 0, sentiment_class: 0, value: 0.0006735344650223851\n",
      "True stock_class: 0, sentiment_class: 0, value: 3.0091839122500103e-12\n",
      "---\n",
      "Example 99:\n",
      "Predicted stock_class: 1, sentiment_class: 2, value: -0.03572288528084755\n",
      "True stock_class: 1, sentiment_class: 2, value: -0.027643386547465475\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# reality check\n",
    "\n",
    "for i in range(100):\n",
    "    stock_label, sentiment_label, value = predict(model, train_dataset[i], scaler)\n",
    "    print(f'Example {i}:')\n",
    "    print(f'Predicted stock_class: {stock_label}, sentiment_class: {sentiment_label}, value: {value}')\n",
    "    print(f'True stock_class: {train_dataset[i][\"stock_labels\"].item()}, sentiment_class: {train_dataset[i][\"sentiment_labels\"].item()}, value: {scaler.inverse_transform([[train_dataset[i][\"values\"].item()]])[0][0]}')\n",
    "    print(\"---\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:07:18.374141Z",
     "start_time": "2023-11-19T06:07:18.006004Z"
    }
   },
   "id": "25312eb729ff53d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0b14be53516d4ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee8a397955f53f54"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T02:13:03.966576Z",
     "start_time": "2023-11-19T02:13:03.953830Z"
    }
   },
   "id": "18252e101acba8ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcff6e512a59c846"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f36bfbbf61d2daa0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1627e6cdc7505b17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing model saving and loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe5619e2f9d7a0ed"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"082_081.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:25:38.100706Z",
     "start_time": "2023-11-19T03:25:38.050903Z"
    }
   },
   "id": "3b13583bfacf1b8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30c648081ed69f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b70ecf111c730259"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def prepare_input(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Takes a string, tokenizes, and prepares it into expected format (list of token ids, attention masks, etc.) ready for model input\n",
    "\n",
    "    Arguments:\n",
    "    text -- string, Raw text string\n",
    "    tokenizer -- transformers.Tokenizer, Initialized tokenizer\n",
    "\n",
    "    Returns:\n",
    "    input_dict -- dictionary, Contains required inputs for model\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        truncation=True, \n",
    "        padding=True,\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Get the input ids and attention masks from tokenizer and convert to tensors\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # Put all tensor entries into a single dictionary\n",
    "    input_dict = {\n",
    "        'input_ids': input_ids,\n",
    "        'token_type_ids': torch.zeros(input_ids.shape, dtype=torch.long),\n",
    "        'attention_mask': attention_mask,\n",
    "    }\n",
    "    \n",
    "    return input_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:14:56.675489Z",
     "start_time": "2023-11-19T03:14:56.646677Z"
    }
   },
   "id": "fa52ccc47f4e6c11"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:14:58.544577Z",
     "start_time": "2023-11-19T03:14:58.520360Z"
    }
   },
   "id": "6a9d47fbb8fc32e9"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dummy_model = CustomBERTModel()\n",
    "dummy_model.load_state_dict(torch.load('best_model.pt'))\n",
    "dummy_model = dummy_model.to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:14:59.335451Z",
     "start_time": "2023-11-19T03:14:58.706858Z"
    }
   },
   "id": "b0fb16d9eb29b692"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  1052,  8873,  6290,  5344, 25748,  2058,  2825,  8503,  1997,\n           3164,  2436,  1012,   102]]),\n 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = prepare_input(\"Pfizer faces backlash over possible closure of regional office.\", tokenizer)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:14:59.340463Z",
     "start_time": "2023-11-19T03:14:59.335769Z"
    }
   },
   "id": "10a127fd518667c7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def predict_loaded_from_loaded_model(model, res, scaler):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: val.to(device) for key, val in res.items()}  \n",
    "\n",
    "        stock_labels_pred, sentiment_labels_pred, regression_values_pred = model(inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs[\"token_type_ids\"])\n",
    "        \n",
    "        stock_label = torch.argmax(stock_labels_pred, dim=1).item()\n",
    "        sentiment_label = torch.argmax(sentiment_labels_pred, dim=1).item()\n",
    "        regression_value = scaler.inverse_transform(regression_values_pred.cpu().numpy()) # inverse transform of scaling\n",
    "\n",
    "    return stock_label, sentiment_label, regression_value[0][0]  # return the single value "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:14:59.412551Z",
     "start_time": "2023-11-19T03:14:59.408073Z"
    }
   },
   "id": "b9c89f5a978efe12"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "stock_label, sentiment_label, value = predict_loaded_from_loaded_model(dummy_model, res, scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T00:31:21.881250Z",
     "start_time": "2023-11-19T00:31:21.814571Z"
    }
   },
   "id": "8cb3b7d1e2b39a21"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 0, -0.017077213)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_label, sentiment_label, value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T00:31:28.083739Z",
     "start_time": "2023-11-19T00:31:28.053885Z"
    }
   },
   "id": "5e6f59bc68babff7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1682871d528a357"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6afb99e0df3b3c02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "optiver-challenge",
   "language": "python",
   "display_name": "Python Optiver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
